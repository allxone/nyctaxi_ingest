nyctaxi2.sources = source1
nyctaxi2.sinks = sink1 sink2
nyctaxi2.channels = c1 c2

# Folder Source
nyctaxi2.sources.source1.type = avro
nyctaxi2.sources.source1.channels = c1 c2
nyctaxi2.sources.source1.bind = 0.0.0.0
nyctaxi2.sources.source1.port = 4545

# Sinks
nyctaxi2.sinks.sink1.type                       = hdfs
nyctaxi2.sinks.sink1.channel                    = c1
nyctaxi2.sinks.sink1.serializer                 = TEXT
nyctaxi2.sinks.sink1.batchSize                  = 1000
nyctaxi2.sinks.sink1.hdfs.fileType              = DataStream
nyctaxi2.sinks.sink1.hdfs.path                  = /data/samples/nyctaxi/trip_part/m12
nyctaxi2.sinks.sink1.hdfs.filePrefix            = tripdata
nyctaxi2.sinks.sink1.hdfs.fileSuffix            = .csv
nyctaxi2.sinks.sink1.hdfs.inUsePrefix           = _
nyctaxi2.sinks.sink1.hdfs.rollInterval          = 60
nyctaxi2.sinks.sink1.hdfs.rollCount             = 0
nyctaxi2.sinks.sink1.hdfs.rollSize              = 10485760

nyctaxi2.sinks.sink2.type = org.apache.spark.streaming.flume.sink.SparkSink
nyctaxi2.sinks.sink2.channel = c2
nyctaxi2.sinks.sink2.hostname = icteam-hadoop31.icteam.local
nyctaxi2.sinks.sink2.port = 4546

# Channels
nyctaxi2.channels.c1.type = memory
nyctaxi2.channels.c1.capacity = 1000
nyctaxi2.channels.c1.transactionCapacity = 100

nyctaxi2.channels.c2.type = memory
nyctaxi2.channels.c2.capacity = 100000
nyctaxi2.channels.c2.transactionCapacity = 10000
